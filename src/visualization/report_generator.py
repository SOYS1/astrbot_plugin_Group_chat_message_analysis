"""
æŠ¥å‘Šç”Ÿæˆå™¨æ¨¡å—
è´Ÿè´£ç”Ÿæˆè¯é¢˜åˆ†æçš„å¯è§†åŒ–æŠ¥å‘Š
"""

from typing import Dict, Any, List
import base64
from datetime import datetime
from astrbot.api import logger


class ReportGenerator:
    def __init__(self):
        pass

    async def generate_topic_analysis_image(self, analysis_result: Dict, keyword: str, group_id: str, html_render_func) -> str:
        """
        ç”Ÿæˆè¯é¢˜åˆ†æçš„å›¾ç‰‡æŠ¥å‘Š
        
        Args:
            analysis_result: åˆ†æç»“æœ
            keyword: åˆ†æçš„å…³é”®è¯
            group_id: ç¾¤å·
            html_render_func: HTMLæ¸²æŸ“å‡½æ•°
            
        Returns:
            å›¾ç‰‡URL
        """
        try:
            # å‡†å¤‡æ¸²æŸ“æ•°æ®
            render_data = self._prepare_render_data(analysis_result, keyword, group_id)
            
            # ä½¿ç”¨AstrBotå†…ç½®çš„HTMLæ¸²æŸ“æœåŠ¡ï¼ˆä¼ é€’æ¨¡æ¿å’Œæ•°æ®ï¼‰
            # ä¿®å¤APIè°ƒç”¨æ–¹å¼ï¼Œç¡®ä¿ä¼ é€’dataå‚æ•°
            template_content = self._get_image_template()
            image_url = await html_render_func(template_content, data=render_data)
            
            return image_url
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›¾ç‰‡æŠ¥å‘Šå¤±è´¥: {e}")
            return ""

    def _prepare_render_data(self, analysis_result: Dict, keyword: str, group_id: str) -> Dict:
        """
        å‡†å¤‡æ¸²æŸ“æ•°æ®
        """
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        current_time = datetime.now().strftime('%H:%M:%S')
        
        # ç”Ÿæˆä¸»è¦è´¡çŒ®è€…HTML
        top_contributors_html = self._generate_top_contributors_for_template(analysis_result['top_contributors'])
        
        # ç”Ÿæˆå…³é”®è®¨è®ºå†…å®¹HTML
        key_discussions_html = self._generate_key_discussions_for_template(analysis_result['key_discussions'])
        
        # ç”Ÿæˆè®¨è®ºä¼šè¯HTML
        discussion_sessions_html = self._generate_discussion_sessions_for_template(analysis_result['discussion_sessions'])
        
        return {
            'current_date': current_date,
            'current_time': current_time,
            'keyword': keyword,
            'group_id': group_id,
            'total_messages': analysis_result['total_messages'],
            'participant_count': len(analysis_result['participants']),
            'contributor_count': len(analysis_result['top_contributors']),
            'session_count': len(analysis_result['discussion_sessions']),
            'topic_summary': analysis_result.get('topic_summary', f'å…³äº"{keyword}"è¯é¢˜çš„åˆ†æç»“æœ'),
            'top_contributors_html': top_contributors_html,
            'key_discussions_html': key_discussions_html,
            'discussion_sessions_html': discussion_sessions_html
        }

    def _get_image_template(self) -> str:
        """
        è·å–å›¾ç‰‡æŠ¥å‘Šçš„HTMLæ¨¡æ¿ï¼ˆä½¿ç”¨AstrBotå…¼å®¹çš„æ¨¡æ¿è¯­æ³•ï¼‰
        """
        return """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Noto Sans SC', 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
            min-height: 100vh; padding: 20px; line-height: 1.6; color: #1a1a1a;
        }
        .container { max-width: 1200px; margin: 0 auto; background: #ffffff; border-radius: 16px; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.08); overflow: hidden; }
        .header { background: linear-gradient(135deg, #4299e1 0%, #667eea 100%); color: #ffffff; padding: 48px 40px; text-align: center; border-radius: 24px 24px 0 0; }
        .header h1 { font-size: 2.5em; font-weight: 300; margin-bottom: 12px; letter-spacing: -1px; }
        .header .date { font-size: 1em; opacity: 0.8; font-weight: 300; letter-spacing: 0.5px; }
        .content { padding: 32px; }
        .section { margin-bottom: 40px; }
        .section-title { font-size: 1.5em; font-weight: 600; margin-bottom: 24px; color: #4a5568; letter-spacing: -0.3px; display: flex; align-items: center; gap: 12px; border-bottom: 2px solid #e2e8f0; padding-bottom: 12px; }
        .stats-grid { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-bottom: 32px; }
        .stat-card { background: linear-gradient(135deg, #f7fafc 0%, #edf2f7 100%); padding: 32px 24px; text-align: center; border-radius: 20px; border: 1px solid #e2e8f0; transition: all 0.3s ease; }
        .stat-card:hover { background: linear-gradient(135deg, #ffffff 0%, #f7fafc 100%); transform: translateY(-4px); box-shadow: 0 12px 32px rgba(102, 126, 234, 0.15); }
        .stat-number { font-size: 2.5em; font-weight: 300; color: #4299e1; margin-bottom: 8px; display: block; letter-spacing: -1px; }
        .stat-label { font-size: 0.9em; color: #666666; font-weight: 500; text-transform: uppercase; letter-spacing: 1px; }
        .contributors { display: flex; flex-wrap: wrap; gap: 12px; }
        .contributor { background: linear-gradient(135deg, #e9f5ff 0%, #d1e7ff 100%); padding: 12px 20px; border-radius: 24px; font-size: 0.9em; font-weight: 500; box-shadow: 0 2px 8px rgba(66, 153, 225, 0.15); }
        .discussion-item { background: #ffffff; padding: 16px; margin-bottom: 12px; border-radius: 12px; border: 1px solid #e5e5e5; transition: all 0.3s ease; }
        .discussion-item:hover { background: #f8f9fa; transform: translateY(-2px); box-shadow: 0 8px 24px rgba(0, 0, 0, 0.08); }
        .discussion-sender { font-weight: 600; color: #4299e1; margin-bottom: 8px; }
        .discussion-content { margin: 8px 0; color: #333; line-height: 1.5; font-size: 0.95em; }
        .discussion-time { font-size: 0.8em; color: #999; }
        
        /* åŒæ’å¹¶åˆ—å¸ƒå±€æ ·å¼ */
        .sessions-container { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        .session-item { background: #ffffff; padding: 20px; margin-bottom: 20px; border-radius: 12px; border: 1px solid #e5e5e5; transition: all 0.3s ease; }
        .session-item:hover { background: #f8f9fa; transform: translateY(-2px); box-shadow: 0 8px 24px rgba(0, 0, 0, 0.08); }
        .session-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 16px; padding-bottom: 12px; border-bottom: 1px solid #eee; }
        .session-title { font-weight: 600; color: #4299e1; font-size: 1.1em; }
        .session-duration { background: #4299e1; color: white; padding: 4px 12px; border-radius: 12px; font-size: 0.8em; font-weight: 600; }
        .session-message { background: #f8f9fa; padding: 12px; margin: 8px 0; border-radius: 8px; border-left: 3px solid #4299e1; }
        .session-sender { font-weight: 600; color: #4299e1; font-size: 0.9em; }
        .session-text { margin: 8px 0; color: #333; font-size: 0.95em; }
        .session-time { font-size: 0.8em; color: #999; }
        .session-status { margin-top: 16px; padding: 12px; border-radius: 8px; font-size: 0.9em; }
        .session-completed { background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%); border: 1px solid #bbf7d0; color: #166534; }
        .session-incomplete { background: linear-gradient(135deg, #fff7ed 0%, #fed7aa 100%); border: 1px solid #fdba74; color: #c2410c; }
        .session-result { font-weight: 500; margin-top: 8px; }
        
        .summary-box { background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%); padding: 24px; border-radius: 16px; border: 1px solid #bae6fd; margin: 24px 0; }
        .summary-title { font-size: 1.2em; font-weight: 600; color: #0369a1; margin-bottom: 12px; display: flex; align-items: center; gap: 8px; }
        .summary-content { color: #0891b2; line-height: 1.7; }
        .footer { background: linear-gradient(135deg, #3182ce 0%, #2c5282 100%); color: #ffffff; text-align: center; padding: 32px; font-size: 0.8em; font-weight: 300; letter-spacing: 0.5px; opacity: 0.9; }
        
        @media (max-width: 768px) {
            body { padding: 10px; }
            .container { margin: 0; max-width: 100%; }
            .header { padding: 24px 20px; }
            .header h1 { font-size: 1.8em; }
            .content { padding: 20px; }
            .stats-grid { grid-template-columns: 1fr 1fr; gap: 12px; }
            .stat-card { padding: 20px 16px; }
            .sessions-container { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š</h1>
            <div class="date">{current_date}</div>
        </div>
        <div class="content">
            <div class="section">
                <h2 class="section-title">ğŸ“ˆ åŸºç¡€ç»Ÿè®¡</h2>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number">{total_messages}</div>
                        <div class="stat-label">ç›¸å…³æ¶ˆæ¯æ•°</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{participant_count}</div>
                        <div class="stat-label">å‚ä¸äººæ•°</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{contributor_count}</div>
                        <div class="stat-label">æ´»è·ƒç”¨æˆ·</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{session_count}</div>
                        <div class="stat-label">è®¨è®ºä¼šè¯</div>
                    </div>
                </div>
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ† ä¸»è¦è´¡çŒ®è€…</h2>
                <div class="contributors">
                    {top_contributors_html}
                </div>
            </div>
            
            <div class="summary-box">
                <div class="summary-title">ğŸ“‹ è¯é¢˜æ€»ç»“</div>
                <div class="summary-content">
                    {topic_summary}
                </div>
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ’¬ å…³é”®è®¨è®ºå†…å®¹</h2>
                {key_discussions_html}
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ”— è®¨è®ºä¼šè¯</h2>
                <div class="sessions-container">
                    {discussion_sessions_html}
                </div>
            </div>
        </div>
        <div class="footer">
            ç”± AstrBot ç¾¤èŠè¯é¢˜åˆ†ææ’ä»¶ ç”Ÿæˆ | {current_date} {current_time}<br>
            ç¾¤å·: {group_id} | å…³é”®è¯: {keyword}
        </div>
    </div>
</body>
</html>"""

    def _generate_top_contributors_for_template(self, top_contributors: Dict) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆä¸»è¦è´¡çŒ®è€…HTML
        """
        if not top_contributors:
            return "<div style='color: #666;'>æš‚æ— è´¡çŒ®è€…æ•°æ®</div>"
        
        contributors_html = ""
        for i, (name, count) in enumerate(list(top_contributors.items())[:15]):
            contributors_html += f'<div class="contributor">{name} ({count}æ¡)</div>'
        
        return contributors_html

    def _generate_key_discussions_for_template(self, key_discussions: List[Dict]) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆå…³é”®è®¨è®ºå†…å®¹HTML
        """
        if not key_discussions:
            return "<div style='color: #666; text-align: center; padding: 20px;'>æš‚æ— è®¨è®ºå†…å®¹</div>"
        
        discussions_html = ""
        for i, discussion in enumerate(key_discussions[:15]):
            # æ ¼å¼åŒ–æ—¶é—´
            time_str = datetime.fromtimestamp(discussion['time']).strftime('%m-%d %H:%M')
            
            discussions_html += f"""
            <div class="discussion-item">
                <div class="discussion-sender">{discussion['sender']}</div>
                <div class="discussion-content">{discussion['content']}</div>
                <div class="discussion-time">{time_str}</div>
            </div>
            """
        
        return discussions_html

    def _generate_discussion_sessions_for_template(self, discussion_sessions: List[Dict]) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆè®¨è®ºä¼šè¯HTML
        """
        if not discussion_sessions:
            return "<div style='color: #666; text-align: center; padding: 20px; grid-column: 1 / -1;'>æš‚æ— è®¨è®ºä¼šè¯</div>"
        
        sessions_html = ""
        for i, session in enumerate(discussion_sessions[:10]):
            messages_html = ""
            for msg in session['messages'][:8]:  # é™åˆ¶æ¯ä¸ªä¼šè¯çš„æ¶ˆæ¯æ•°
                time_str = datetime.fromtimestamp(msg['time']).strftime('%H:%M')
                messages_html += f"""
                <div class="session-message">
                    <div class="session-sender">{msg['sender']}</div>
                    <div class="session-text">{msg['content']}</div>
                    <div class="session-time">{time_str}</div>
                </div>
                """
            
            # ä¼šè¯çŠ¶æ€æ˜¾ç¤º
            status_class = "session-completed" if session['status']['is_completed'] else "session-incomplete"
            status_text = "å·²å®Œæˆ" if session['status']['is_completed'] else "æœªå®Œæˆ"
            result_text = session['status']['result_summary']
            
            sessions_html += f"""
            <div class="session-item">
                <div class="session-header">
                    <div class="session-title">ä¼šè¯ #{i+1}</div>
                    <div class="session-duration">{session['message_count']}æ¡æ¶ˆæ¯</div>
                </div>
                {messages_html}
                <div class="session-status {status_class}">
                    çŠ¶æ€: {status_text}
                    <div class="session-result">ç»“æœ: {result_text}</div>
                </div>
            </div>
            """
        
        return sessions_html

    def generate_text_report(self, analysis_result: Dict) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Š
        """
        report = f"""
=== ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š ===
å…³é”®è¯: {analysis_result['keyword']}
ç¾¤å·: {analysis_result['group_id']}
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
- ç›¸å…³æ¶ˆæ¯æ•°: {analysis_result['total_messages']}
- å‚ä¸äººæ•°: {len(analysis_result['participants'])}
- æ´»è·ƒç”¨æˆ·: {len(analysis_result['top_contributors'])}
- è®¨è®ºä¼šè¯: {len(analysis_result['discussion_sessions'])}

ğŸ† ä¸»è¦è´¡çŒ®è€…:
        """
        
        for name, count in list(analysis_result['top_contributors'].items())[:10]:
            report += f"- {name}: {count}æ¡æ¶ˆæ¯\n"
        
        report += f"\nğŸ“‹ è¯é¢˜æ€»ç»“:\n{analysis_result.get('topic_summary', 'æš‚æ— æ™ºèƒ½åˆ†æç»“æœ')}"
        
        report += "\n\nğŸ’¬ å…³é”®è®¨è®ºå†…å®¹:\n"
        for i, discussion in enumerate(analysis_result['key_discussions'][:8], 1):
            time_str = datetime.fromtimestamp(discussion['time']).strftime('%m-%d %H:%M')
            report += f"{i}. {discussion['sender']} ({time_str}): {discussion['content']}\n"
        
        report += "\nğŸ”— è®¨è®ºä¼šè¯:\n"
        for i, session in enumerate(analysis_result['discussion_sessions'][:5], 1):
            start_time = datetime.fromtimestamp(session['start_time']).strftime('%m-%d %H:%M')
            end_time = datetime.fromtimestamp(session['end_time']).strftime('%H:%M')
            status = "å·²å®Œæˆ" if session['status']['is_completed'] else "æœªå®Œæˆ"
            result = session['status']['result_summary']
            
            report += f"ä¼šè¯ {i} ({session['message_count']}æ¡æ¶ˆæ¯, {start_time}-{end_time}, {status}):\n"
            report += f"  ç»“æœ: {result}\n"
            
            for j, msg in enumerate(session['messages'][:5], 1):
                time_str = datetime.fromtimestamp(msg['time']).strftime('%H:%M')
                report += f"  {j}. {msg['sender']} ({time_str}): {msg['content']}\n"
            report += "\n"
        
        return report                        logger.warning(f"ç¾¤ {group_id} APIè¿”å›æ— æ•ˆç»“æœ: {result}")
                        consecutive_failures += 1
                        if consecutive_failures >= max_failures:
                            break
                        continue

                    round_messages = result.get("messages", [])
                    
                    if not round_messages:
                        logger.info(f"ç¾¤ {group_id} æ²¡æœ‰æ›´å¤šæ¶ˆæ¯ï¼Œç»“æŸè·å–")
                        break

                    # é‡ç½®å¤±è´¥è®¡æ•°
                    consecutive_failures = 0

                    # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ¶ˆæ¯
                    valid_messages_in_round = 0
                    oldest_msg_time = None

                    for msg in round_messages:
                        try:
                            msg_time = datetime.fromtimestamp(msg.get("time", 0))
                            oldest_msg_time = msg_time

                            # è¿‡æ»¤æ—¶é—´èŒƒå›´
                            if msg_time < start_time or msg_time > end_time:
                                continue

                            # å¦‚æœæä¾›äº†å…³é”®è¯ï¼Œä½¿ç”¨è¯­ä¹‰ç›¸å…³åŒ¹é…
                            if keyword:
                                if not self._is_semantically_related(msg, keyword_variants):
                                    continue

                            messages.append(msg)
                            valid_messages_in_round += 1
                        except Exception as msg_error:
                            logger.warning(f"ç¾¤ {group_id} å¤„ç†å•æ¡æ¶ˆæ¯å¤±è´¥: {msg_error}")
                            continue

                    # å¦‚æœæœ€è€çš„æ¶ˆæ¯æ—¶é—´å·²ç»è¶…å‡ºèŒƒå›´ï¼Œåœæ­¢è·å–
                    if oldest_msg_time and oldest_msg_time < start_time:
                        logger.info(f"ç¾¤ {group_id} å·²è·å–åˆ°æ—¶é—´èŒƒå›´å¤–çš„æ¶ˆæ¯ï¼Œåœæ­¢è·å–ã€‚å…±è·å– {len(messages)} æ¡æ¶ˆæ¯")
                        break

                    if valid_messages_in_round == 0:
                        logger.warning(f"ç¾¤ {group_id} æœ¬è½®æœªè·å–åˆ°æœ‰æ•ˆæ¶ˆæ¯")
                        break

                    message_seq = round_messages[0]["message_id"]
                    query_rounds += 1

                except Exception as e:
                    logger.error(f"ç¾¤ {group_id} è·å–æ¶ˆæ¯å¤±è´¥: {e}")
                    consecutive_failures += 1
                    if consecutive_failures >= max_failures:
                        break
                    await asyncio.sleep(1)

            logger.info(f"ç¾¤ {group_id} æœ€ç»ˆè·å– {len(messages)} æ¡ç›¸å…³æ¶ˆæ¯")
            return messages

        except Exception as e:
            logger.error(f"è·å–ç¾¤ {group_id} æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []

    def _expand_keyword_variants(self, keyword: str) -> List[str]:
        """
        æ™ºèƒ½è¯­ä¹‰æ‰©å±•ç³»ç»Ÿ - æ— éœ€é¢„å®šä¹‰è¯å…¸
        åŸºäºå­—ç¬¦ç›¸ä¼¼åº¦ã€ç½‘ç»œç”¨è¯­å˜å½¢ã€ä¸Šä¸‹æ–‡æ¨¡å¼è¯†åˆ«
        
        Args:
            keyword: ä»»æ„å…³é”®è¯
            
        Returns:
            åŠ¨æ€ç”Ÿæˆçš„è¯­ä¹‰ç›¸å…³è¯æ±‡åˆ—è¡¨
        """
        keyword = keyword.lower().strip()
        if not keyword:
            return []
        
        variants = [keyword]
        
        # 1. å­—ç¬¦çº§æ™ºèƒ½å˜å½¢
        variants.extend(self._generate_char_variants(keyword))
        
        # 2. ç½‘ç»œç”¨è¯­æ™ºèƒ½è¯†åˆ«
        variants.extend(self._generate_internet_variants(keyword))
        
        # 3. è¯­ä¹‰åœºåŠ¨æ€æ‰©å±•
        variants.extend(self._generate_semantic_variants(keyword))
        
        # 4. ä¸Šä¸‹æ–‡æ¨¡å¼åŒ¹é…
        variants.extend(self._generate_contextual_variants(keyword))
        
        # 5. æ¨¡ç³ŠåŒ¹é…å˜ä½“
        variants.extend(self._generate_fuzzy_variants(keyword))
        
        # å»é‡å¹¶æ’åºï¼ˆæŒ‰ç›¸å…³åº¦ï¼‰
        seen = set()
        unique_variants = []
        for variant in variants:
            variant = variant.strip()
            if variant and variant != keyword and variant not in seen:
                seen.add(variant)
                # è®¡ç®—ç›¸å…³åº¦åˆ†æ•°ç”¨äºæ’åº
                score = self._calculate_relevance_score(keyword, variant)
                unique_variants.append((variant, score))
        
        # æŒ‰ç›¸å…³åº¦æ’åºï¼Œå–å‰30ä¸ª
        unique_variants.sort(key=lambda x: x[1], reverse=True)
        final_variants = [keyword] + [item[0] for item in unique_variants[:30]]
        
        logger.info(f"æ™ºèƒ½æ‰©å±• '{keyword}' â†’ {len(final_variants)}ä¸ªå˜ä½“: {final_variants}")
        return final_variants

    def _generate_char_variants(self, keyword: str) -> List[str]:
        """å­—ç¬¦çº§æ™ºèƒ½å˜å½¢"""
        variants = []
        
        # é‡å¤å­—å˜ä½“
        if len(keyword) <= 4:
            variants.append(keyword + keyword)
            if len(keyword) >= 2:
                variants.append(keyword[0] + keyword)
                variants.append(keyword + keyword[-1])
        
        # å‰åç¼€
        prefixes = ["å¤§", "å°", "è€", "æ–°", "è¶…çº§", "çœŸçš„", "å‡çš„"]
        suffixes = ["äº†", "çš„", "ä¸€ä¸‹", "äº†", "äº†", "å•Š", "å‘€", "å‘¢"]
        
        for prefix in prefixes:
            variants.append(prefix + keyword)
        
        for suffix in suffixes:
            variants.append(keyword + suffix)
        
        return variants

    def _generate_internet_variants(self, keyword: str) -> List[str]:
        """ç½‘ç»œç”¨è¯­æ™ºèƒ½è¯†åˆ«"""
        variants = []
        
        # æ•°å­—æ›¿æ¢
        num_replacements = {
            'o': '0', 'i': '1', 'l': '1', 'z': '2', 'e': '3', 'a': '4', 
            's': '5', 't': '7', 'b': '6', 'g': '9', 'q': '9'
        }
        
        # ç½‘ç»œæµè¡Œè¯­æ¨¡å¼
        internet_patterns = {
            "å­™ç¬‘å·": ["æŠ½è±¡", "å¸¦å¸ˆ", "nm$l", "æ–°æ´¥", "æ¶ä¿—", "ç‹—ç²‰ä¸", "6324", "å—¨ç²‰"],
            "è”¡å¾å¤": ["é¸¡å“¥", "é¸¡ä½ å¤ªç¾", "ç¯®çƒ", "ç»ƒä¹ ç”Ÿ", "ä¸¤å¹´åŠ", "å°é»‘å­"],
            "ä¸çœŸ": ["çç ", "ç†å¡˜", "ç”µå­çƒŸ", "é”åˆ»5", "çº¯çœŸ", "ä¸€çœ¼çœŸ"],
            "é©¬ä¿å›½": ["è€—å­å°¾æ±", "å¹´è½»äººä¸è®²æ­¦å¾·", "ä¼ ç»ŸåŠŸå¤«", "æ¥åŒ–å‘", "é—ªç”µäº”è¿é­"],
            "æèµ£": ["6324", "æŠ½è±¡", "å—¨ç²‰", "ç‹—ç²‰ä¸", "å¸¦æ˜æ˜Ÿ", "å¸¦ç§€"]
        }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œäººç‰©
        for person, related in internet_patterns.items():
            if keyword in person or person in keyword:
                variants.extend(related)
        
        # è°éŸ³æ¢—
        if "ç¬‘" in keyword:
            variants.extend(["å­", "æ ¡", "æ•ˆ", "å•¸"])
        if "å·" in keyword:
            variants.extend(["ç©¿", "ä¼ ", "èˆ¹", "å–˜"])
        if "å¤" in keyword:
            variants.extend(["é²²", "æ˜†", "æ†", "å›°"])
        
        # ç½‘ç»œç¼©å†™
        abbreviations = {
            "yyds": ["æ°¸è¿œçš„ç¥", "æ°¸è¿œæ»´ç¥"],
            "xswl": ["ç¬‘æ­»æˆ‘äº†"],
            "zqsg": ["çœŸæƒ…å®æ„Ÿ"],
            "u1s1": ["æœ‰ä¸€è¯´ä¸€"],
            "dddd": ["æ‡‚çš„éƒ½æ‡‚"]
        }
        
        for abbr, full in abbreviations.items():
            if keyword == abbr:
                variants.extend(full)
            elif keyword in str(full):
                variants.append(abbr)
        
        return variants

    def _generate_semantic_variants(self, keyword: str) -> List[str]:
        """è¯­ä¹‰åœºåŠ¨æ€æ‰©å±•"""
        variants = []
        
        # åŸºäºå…³é”®è¯ç±»å‹çš„è¯­ä¹‰æ‰©å±•
        if len(keyword) <= 3:
            # çŸ­è¯æ‰©å±•
            if keyword.endswith("å“¥"):
                variants.extend(["å“¥å“¥", "å¤§å“¥", "è€å“¥", "å“¥å„¿", "å“¥å­"])
            elif keyword.endswith("å§"):
                variants.extend(["å§å§", "å¤§å§", "è€å§", "å§å„¿"])
            elif keyword.endswith("å¼Ÿ"):
                variants.extend(["å¼Ÿå¼Ÿ", "å°å¼Ÿ", "è€å¼Ÿ", "å¼Ÿå„¿"])
            elif keyword.endswith("å¦¹"):
                variants.extend(["å¦¹å¦¹", "å°å¦¹", "è€å¦¹", "å¦¹å„¿"])
        
        # æƒ…æ„Ÿè¯æ‰©å±•
        emotion_words = ["å–œæ¬¢", "è®¨åŒ", "çˆ±", "æ¨", "æƒ³", "å¿µ", "çƒ¦", "æ„", "å¼€å¿ƒ", "éš¾è¿‡"]
        for emotion in emotion_words:
            variants.append(emotion + keyword)
            variants.append(keyword + emotion)
        
        # åŠ¨ä½œè¯æ‰©å±•
        action_words = ["çœ‹", "å¬", "è¯´", "æƒ³", "åš", "ç©", "å­¦", "åƒ", "å–", "ä¹°"]
        for action in action_words:
            variants.append(action + keyword)
            variants.append(keyword + action)
        
        return variants

    def _generate_contextual_variants(self, keyword: str) -> List[str]:
        """ä¸Šä¸‹æ–‡æ¨¡å¼åŒ¹é…"""
        variants = []
        
        # åŸºäºä½¿ç”¨åœºæ™¯çš„ä¸Šä¸‹æ–‡è¯
        contexts = {
            "äººå": ["è¿™ä¸ªäºº", "è¿™ä½", "å¤§ä½¬", "è€å¸ˆ", "å“¥", "å§", "å…„å¼Ÿ", "æœ‹å‹"],
            "åœ°ç‚¹": ["åœ¨", "å»", "åˆ°", "ä»", "æ¥", "å›", "è·¯è¿‡", "ç»è¿‡"],
            "æ—¶é—´": ["ä»Šå¤©", "æ˜¨å¤©", "æ˜å¤©", "åˆšæ‰", "åˆšåˆš", "ç°åœ¨", "ä»¥å", "ä»¥å‰"],
            "è¯„ä»·": ["çœŸçš„", "å‡çš„", "å¤ª", "å¾ˆ", "è¶…çº§", "ç‰¹åˆ«", "éå¸¸", "æœ‰ç‚¹", "ç¨å¾®"]
        }
        
        # æ ¹æ®å…³é”®è¯ç‰¹å¾æ·»åŠ ä¸Šä¸‹æ–‡
        for context_type, context_words in contexts.items():
            for context in context_words:
                variants.append(context + keyword)
                variants.append(keyword + context)
        
        return variants

    def _generate_fuzzy_variants(self, keyword: str) -> List[str]:
        """æ¨¡ç³ŠåŒ¹é…å˜ä½“"""
        variants = []
        
        # ç¼–è¾‘è·ç¦»1çš„å˜ä½“ï¼ˆæ’å…¥ã€åˆ é™¤ã€æ›¿æ¢ï¼‰
        if len(keyword) >= 2:
            # åˆ é™¤ä¸€ä¸ªå­—ç¬¦
            for i in range(len(keyword)):
                variants.append(keyword[:i] + keyword[i+1:])
            
            # æ’å…¥å¸¸è§å­—ç¬¦
            common_chars = ["çš„", "äº†", "å­", "å„¿", "å•Š", "å‘€", "å‘¢", "å§"]
            for char in common_chars:
                for i in range(len(keyword) + 1):
                    variants.append(keyword[:i] + char + keyword[i:])
            
            # æ›¿æ¢ç›¸ä¼¼å­—ç¬¦
            similar_chars = {
                'ç¬‘': 'å­', 'å·': 'ç©¿', 'å­™': 'æŸ', 'å¤': 'é²²',
                'è”¡': 'èœ', 'å¾': 'è®¸', 'ä¸': 'é’‰', 'çœŸ': 'é’ˆ'
            }
            for original, similar in similar_chars.items():
                if original in keyword:
                    variants.append(keyword.replace(original, similar))
        
        return variants

    def _calculate_relevance_score(self, original: str, variant: str) -> float:
        """è®¡ç®—è¯æ±‡ç›¸å…³åº¦åˆ†æ•°"""
        if original == variant:
            return 100.0
        
        score = 0.0
        
        # ç¼–è¾‘è·ç¦»åˆ†æ•°
        import difflib
        similarity = difflib.SequenceMatcher(None, original, variant).ratio()
        score += similarity * 50
        
        # åŒ…å«å…³ç³»åˆ†æ•°
        if original in variant or variant in original:
            score += 30
        
        # å­—ç¬¦é‡å åˆ†æ•°
        original_chars = set(original)
        variant_chars = set(variant)
        overlap = len(original_chars.intersection(variant_chars))
        if overlap > 0:
            score += (overlap / len(original_chars)) * 20
        
        return min(score, 100.0)

    def _is_semantically_related(self, message: Dict, keyword_variants: List[str]) -> bool:
        """
        æ™ºèƒ½è¯­ä¹‰å…³è”åˆ¤æ–­ - æ— éœ€è¯å…¸çš„åŠ¨æ€ç†è§£
        æ”¯æŒå­—ç¬¦ç›¸ä¼¼åº¦ã€ç½‘ç»œç”¨è¯­ã€ä¸Šä¸‹æ–‡ç†è§£
        
        Args:
            message: æ¶ˆæ¯å­—å…¸
            keyword_variants: å…³é”®è¯å˜ä½“åˆ—è¡¨
            
        Returns:
            æ˜¯å¦è¯­ä¹‰ç›¸å…³
        """
        try:
            text = message.get('content', '').lower().strip()
            if not text or not keyword_variants:
                return False
            
            original_keyword = keyword_variants[0].lower()
            
            # 1. ç›´æ¥åŒ…å«åŒ¹é…ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
            for variant in keyword_variants:
                if variant in text:
                    logger.info(f"ç›´æ¥åŒ¹é…: '{variant}' åœ¨æ¶ˆæ¯ä¸­")
                    return True
            
            # 2. å­—ç¬¦çº§ç›¸ä¼¼åº¦åŒ¹é…
            similarity_threshold = 0.6
            for variant in keyword_variants:
                similarity = self._calculate_text_similarity(text, variant)
                if similarity >= similarity_threshold:
                    logger.info(f"å­—ç¬¦ç›¸ä¼¼åº¦åŒ¹é…: '{variant}' (ç›¸ä¼¼åº¦: {similarity:.2f})")
                    return True
            
            # 3. åˆ†è¯æ¨¡ç³ŠåŒ¹é…
            if self._fuzzy_word_match(text, keyword_variants):
                return True
            
            # 4. ç½‘ç»œç”¨è¯­æ¨¡å¼åŒ¹é…
            if self._internet_pattern_match(text, original_keyword):
                return True
            
            # 5. ä¸Šä¸‹æ–‡è¯­ä¹‰å…³è”
            if self._contextual_semantic_match(text, original_keyword):
                return True
            
            # 6. æ‹¼éŸ³ç›¸ä¼¼åº¦åŒ¹é…
            if self._pinyin_similarity_match(text, original_keyword):
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰åŒ¹é…å‡ºé”™: {e}")
            # å›é€€åˆ°ç®€å•åŒ…å«åŒ¹é…
            return any(variant in str(message.get('content', '')).lower() 
                      for variant in keyword_variants)

    def _calculate_text_similarity(self, text: str, keyword: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        import difflib
        
        # å­ä¸²ç›¸ä¼¼åº¦
        max_similarity = 0.0
        text_len = len(text)
        keyword_len = len(keyword)
        
        if keyword_len == 0:
            return 0.0
        
        # æ»‘åŠ¨çª—å£è®¡ç®—æœ€å¤§ç›¸ä¼¼åº¦
        for i in range(text_len - keyword_len + 1):
            substring = text[i:i+keyword_len]
            similarity = difflib.SequenceMatcher(None, substring, keyword).ratio()
            max_similarity = max(max_similarity, similarity)
        
        # å­—ç¬¦é‡å åº¦
        text_chars = set(text)
        keyword_chars = set(keyword)
        char_overlap = len(text_chars.intersection(keyword_chars))
        char_similarity = char_overlap / len(keyword_chars) if keyword_chars else 0
        
        return max(max_similarity, char_similarity * 0.8)

    def _fuzzy_word_match(self, text: str, keyword_variants: List[str]) -> bool:
        """åˆ†è¯æ¨¡ç³ŠåŒ¹é…"""
        # ç®€å•çš„åˆ†è¯å®ç°
        def simple_tokenize(text: str) -> List[str]:
            # æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†è¯
            import re
            tokens = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z0-9]+', text)
            return [token.lower() for token in tokens]
        
        text_tokens = simple_tokenize(text)
        
        for keyword in keyword_variants:
            keyword_tokens = simple_tokenize(keyword)
            
            # æ£€æŸ¥æ¯ä¸ªå…³é”®è¯token
            for keyword_token in keyword_tokens:
                for text_token in text_tokens:
                    # ç¼–è¾‘è·ç¦»æ£€æŸ¥
                    if self._levenshtein_distance(keyword_token, text_token) <= 1:
                        logger.info(f"åˆ†è¯æ¨¡ç³ŠåŒ¹é…: '{keyword_token}' ~ '{text_token}'")
                        return True
                    
                    # åŒ…å«å…³ç³»æ£€æŸ¥
                    if keyword_token in text_token or text_token in keyword_token:
                        if len(keyword_token) >= 2 and len(text_token) >= 2:
                            logger.info(f"åˆ†è¯åŒ…å«åŒ¹é…: '{keyword_token}' in '{text_token}'")
                            return True
        
        return False

    def _internet_pattern_match(self, text: str, keyword: str) -> bool:
        """ç½‘ç»œç”¨è¯­æ¨¡å¼åŒ¹é…"""
        # ç½‘ç»œç”¨è¯­æ˜ å°„ï¼ˆåŠ¨æ€è¯†åˆ«ï¼‰
        internet_patterns = {
            "å­™ç¬‘å·": {
                "patterns": ["æŠ½è±¡", "å¸¦å¸ˆ", "nm", "æ–°æ´¥", "æ¶ä¿—", "ç‹—ç²‰ä¸", "6324", "å—¨ç²‰", "å¸¦æ˜æ˜Ÿ"],
                "keywords": ["å­™ç¬‘å·", "ç¬‘å·", "å­™ç¬‘", "ç¬‘å·"]
            },
            "è”¡å¾å¤": {
                "patterns": ["é¸¡å“¥", "é¸¡ä½ å¤ªç¾", "ç¯®çƒ", "ç»ƒä¹ ç”Ÿ", "ä¸¤å¹´åŠ", "å°é»‘å­", "å”±è·³rap"],
                "keywords": ["è”¡å¾å¤", "å¾å¤", "è”¡å¾", "å¤å¤"]
            },
            "ä¸çœŸ": {
                "patterns": ["çç ", "ç†å¡˜", "ç”µå­çƒŸ", "é”åˆ»", "çº¯çœŸ", "ä¸€çœ¼çœŸ", "ä¸çœŸçç "],
                "keywords": ["ä¸çœŸ", "çç ", "ç†å¡˜"]
            }
        }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œäººç‰©ç›¸å…³
        for person, data in internet_patterns.items():
            if any(kw in keyword for kw in data["keywords"]):
                for pattern in data["patterns"]:
                    if pattern.lower() in text.lower():
                        logger.info(f"ç½‘ç»œç”¨è¯­åŒ¹é…: '{person}' ç›¸å…³ '{pattern}'")
                        return True
        
        return False

    def _contextual_semantic_match(self, text: str, keyword: str) -> bool:
        """ä¸Šä¸‹æ–‡è¯­ä¹‰å…³è”"""
        # ä¸Šä¸‹æ–‡å…³é”®è¯æ˜ å°„
        context_keywords = {
            "äººå": ["è¿™ä¸ªäºº", "è¿™ä½", "å¤§ä½¬", "è€å¸ˆ", "å“¥", "å§", "å…„å¼Ÿ", "æœ‹å‹", "ä¸»æ’­", "upä¸»"],
            "äº‹ä»¶": ["å‘ç”Ÿ", "å‡ºç°", "çœ‹åˆ°", "å¬è¯´", "çŸ¥é“", "äº†è§£", "çœ‹åˆ°", "é‡åˆ°"],
            "è¯„ä»·": ["è§‰å¾—", "è®¤ä¸º", "æ„Ÿè§‰", "å¥½åƒ", "ä¼¼ä¹", "å¯èƒ½", "åº”è¯¥", "ç¡®å®"]
        }
        
        # å¦‚æœå…³é”®è¯æ˜¯äººåï¼Œæ£€æŸ¥ä¸Šä¸‹æ–‡
        if len(keyword) <= 4 and any(char in keyword for char in ["å­™", "æ", "å¼ ", "ç‹", "åˆ˜", "é™ˆ", "æ¨", "èµµ", "é»„", "å‘¨"]):
            for category, keywords in context_keywords.items():
                for context_kw in keywords:
                    if context_kw in text:
                        # æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«äººåç‰¹å¾
                        name_patterns = ["[\u4e00-\u9fff]{2,4}", "[A-Z][a-z]+"]
                        import re
                        for pattern in name_patterns:
                            matches = re.findall(pattern, text)
                            for match in matches:
                                if self._calculate_text_similarity(match.lower(), keyword) > 0.5:
                                    logger.info(f"ä¸Šä¸‹æ–‡äººååŒ¹é…: '{keyword}' ~ '{match}'")
                                    return True
        
        return False

    def _pinyin_similarity_match(self, text: str, keyword: str) -> bool:
        """æ‹¼éŸ³ç›¸ä¼¼åº¦åŒ¹é…"""
        try:
            # ç®€å•çš„æ‹¼éŸ³è½¬æ¢ï¼ˆå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨pypinyinåº“ï¼‰
            def simple_pinyin(text: str) -> str:
                # è¿™é‡Œç”¨ç®€åŒ–çš„æ–¹å¼ï¼Œå®é™…åº”è¯¥ä½¿ç”¨pypinyin
                pinyin_map = {
                    'å­™': 'sun', 'ç¬‘': 'xiao', 'å·': 'chuan',
                    'è”¡': 'cai', 'å¾': 'xu', 'å¤': 'kun',
                    'ä¸': 'ding', 'çœŸ': 'zhen'
                }
                result = ""
                for char in text:
                    result += pinyin_map.get(char, char)
                return result
            
            text_pinyin = simple_pinyin(text)
            keyword_pinyin = simple_pinyin(keyword)
            
            similarity = difflib.SequenceMatcher(None, text_pinyin, keyword_pinyin).ratio()
            if similarity >= 0.7:
                logger.info(f"æ‹¼éŸ³ç›¸ä¼¼åº¦åŒ¹é…: '{keyword}' (æ‹¼éŸ³ç›¸ä¼¼åº¦: {similarity:.2f})")
                return True
                
        except Exception as e:
            logger.debug(f"æ‹¼éŸ³åŒ¹é…å‡ºé”™: {e}")
        
        return False

    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]            'topic_summary': analysis_result.get('topic_summary', f'å…³äº"{keyword}"è¯é¢˜çš„åˆ†æç»“æœ'),
            'top_contributors_html': top_contributors_html,
            'key_discussions_html': key_discussions_html,
            'discussion_sessions_html': discussion_sessions_html
        }

    def _get_image_template(self) -> str:
        """
        è·å–å›¾ç‰‡æŠ¥å‘Šçš„HTMLæ¨¡æ¿ï¼ˆä½¿ç”¨{{ }}å ä½ç¬¦ï¼‰
        """
        return """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š - {{ keyword }}</title>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Noto Sans SC', 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
            min-height: 100vh; padding: 20px; line-height: 1.6; color: #1a1a1a;
        }
        .container { max-width: 1200px; margin: 0 auto; background: #ffffff; border-radius: 16px; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.08); overflow: hidden; }
        .header { background: linear-gradient(135deg, #4299e1 0%, #667eea 100%); color: #ffffff; padding: 48px 40px; text-align: center; border-radius: 24px 24px 0 0; }
        .header h1 { font-size: 2.5em; font-weight: 300; margin-bottom: 12px; letter-spacing: -1px; }
        .header .date { font-size: 1em; opacity: 0.8; font-weight: 300; letter-spacing: 0.5px; }
        .content { padding: 32px; }
        .section { margin-bottom: 40px; }
        .section-title { font-size: 1.5em; font-weight: 600; margin-bottom: 24px; color: #4a5568; letter-spacing: -0.3px; display: flex; align-items: center; gap: 12px; border-bottom: 2px solid #e2e8f0; padding-bottom: 12px; }
        .stats-grid { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-bottom: 32px; }
        .stat-card { background: linear-gradient(135deg, #f7fafc 0%, #edf2f7 100%); padding: 32px 24px; text-align: center; border-radius: 20px; border: 1px solid #e2e8f0; transition: all 0.3s ease; }
        .stat-card:hover { background: linear-gradient(135deg, #ffffff 0%, #f7fafc 100%); transform: translateY(-4px); box-shadow: 0 12px 32px rgba(102, 126, 234, 0.15); }
        .stat-number { font-size: 2.5em; font-weight: 300; color: #4299e1; margin-bottom: 8px; display: block; letter-spacing: -1px; }
        .stat-label { font-size: 0.9em; color: #666666; font-weight: 500; text-transform: uppercase; letter-spacing: 1px; }
        .contributors { display: flex; flex-wrap: wrap; gap: 12px; }
        .contributor { background: linear-gradient(135deg, #e9f5ff 0%, #d1e7ff 100%); padding: 12px 20px; border-radius: 24px; font-size: 0.9em; font-weight: 500; box-shadow: 0 2px 8px rgba(66, 153, 225, 0.15); }
        .discussion-item { background: #ffffff; padding: 16px; margin-bottom: 12px; border-radius: 12px; border: 1px solid #e5e5e5; transition: all 0.3s ease; }
        .discussion-item:hover { background: #f8f9fa; transform: translateY(-2px); box-shadow: 0 8px 24px rgba(0, 0, 0, 0.08); }
        .discussion-sender { font-weight: 600; color: #4299e1; margin-bottom: 8px; }
        .discussion-content { margin: 8px 0; color: #333; line-height: 1.5; font-size: 0.95em; }
        .discussion-time { font-size: 0.8em; color: #999; }
        
        /* åŒæ’å¹¶åˆ—å¸ƒå±€æ ·å¼ */
        .sessions-container { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
        .session-item { background: #ffffff; padding: 20px; margin-bottom: 20px; border-radius: 12px; border: 1px solid #e5e5e5; transition: all 0.3s ease; }
        .session-item:hover { background: #f8f9fa; transform: translateY(-2px); box-shadow: 0 8px 24px rgba(0, 0, 0, 0.08); }
        .session-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 16px; padding-bottom: 12px; border-bottom: 1px solid #eee; }
        .session-title { font-weight: 600; color: #4299e1; font-size: 1.1em; }
        .session-duration { background: #4299e1; color: white; padding: 4px 12px; border-radius: 12px; font-size: 0.8em; font-weight: 600; }
        .session-message { background: #f8f9fa; padding: 12px; margin: 8px 0; border-radius: 8px; border-left: 3px solid #4299e1; }
        .session-sender { font-weight: 600; color: #4299e1; font-size: 0.9em; }
        .session-text { margin: 8px 0; color: #333; font-size: 0.95em; }
        .session-time { font-size: 0.8em; color: #999; }
        .session-status { margin-top: 16px; padding: 12px; border-radius: 8px; font-size: 0.9em; }
        .session-completed { background: linear-gradient(135deg, #f0fdf4 0%, #dcfce7 100%); border: 1px solid #bbf7d0; color: #166534; }
        .session-incomplete { background: linear-gradient(135deg, #fff7ed 0%, #fed7aa 100%); border: 1px solid #fdba74; color: #c2410c; }
        .session-result { font-weight: 500; margin-top: 8px; }
        
        .summary-box { background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%); padding: 24px; border-radius: 16px; border: 1px solid #bae6fd; margin: 24px 0; }
        .summary-title { font-size: 1.2em; font-weight: 600; color: #0369a1; margin-bottom: 12px; display: flex; align-items: center; gap: 8px; }
        .summary-content { color: #0891b2; line-height: 1.7; }
        .footer { background: linear-gradient(135deg, #3182ce 0%, #2c5282 100%); color: #ffffff; text-align: center; padding: 32px; font-size: 0.8em; font-weight: 300; letter-spacing: 0.5px; opacity: 0.9; }
        
        @media (max-width: 768px) {
            body { padding: 10px; }
            .container { margin: 0; max-width: 100%; }
            .header { padding: 24px 20px; }
            .header h1 { font-size: 1.8em; }
            .content { padding: 20px; }
            .stats-grid { grid-template-columns: 1fr 1fr; gap: 12px; }
            .stat-card { padding: 20px 16px; }
            .sessions-container { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š</h1>
            <div class="date">{{ current_date }}</div>
        </div>
        <div class="content">
            <div class="section">
                <h2 class="section-title">ğŸ“ˆ åŸºç¡€ç»Ÿè®¡</h2>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number">{{ total_messages }}</div>
                        <div class="stat-label">ç›¸å…³æ¶ˆæ¯æ•°</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{{ participant_count }}</div>
                        <div class="stat-label">å‚ä¸äººæ•°</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{{ contributor_count }}</div>
                        <div class="stat-label">æ´»è·ƒç”¨æˆ·</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">{{ session_count }}</div>
                        <div class="stat-label">è®¨è®ºä¼šè¯</div>
                    </div>
                </div>
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ† ä¸»è¦è´¡çŒ®è€…</h2>
                <div class="contributors">
                    {{ top_contributors_html | safe }}
                </div>
            </div>
            
            <div class="summary-box">
                <div class="summary-title">ğŸ“‹ è¯é¢˜æ€»ç»“</div>
                <div class="summary-content">
                    {{ topic_summary }}
                </div>
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ’¬ å…³é”®è®¨è®ºå†…å®¹</h2>
                {{ key_discussions_html | safe }}
            </div>
            
            <div class="section">
                <h2 class="section-title">ğŸ”— è®¨è®ºä¼šè¯</h2>
                <div class="sessions-container">
                    {{ discussion_sessions_html | safe }}
                </div>
            </div>
        </div>
        <div class="footer">
            ç”± AstrBot ç¾¤èŠè¯é¢˜åˆ†ææ’ä»¶ ç”Ÿæˆ | {{ current_date }} {{ current_time }}<br>
            ç¾¤å·: {{ group_id }} | å…³é”®è¯: {{ keyword }}
        </div>
    </div>
</body>
</html>"""

    def _generate_top_contributors_for_template(self, top_contributors: Dict) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆä¸»è¦è´¡çŒ®è€…HTML
        """
        if not top_contributors:
            return "<div style='color: #666;'>æš‚æ— è´¡çŒ®è€…æ•°æ®</div>"
        
        contributors_html = ""
        for i, (name, count) in enumerate(list(top_contributors.items())[:15]):
            contributors_html += f'<div class="contributor">{name} ({count}æ¡)</div>'
        
        return contributors_html

    def _generate_key_discussions_for_template(self, key_discussions: List[Dict]) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆå…³é”®è®¨è®ºå†…å®¹HTML
        """
        if not key_discussions:
            return "<div style='color: #666; text-align: center; padding: 20px;'>æš‚æ— è®¨è®ºå†…å®¹</div>"
        
        discussions_html = ""
        for i, discussion in enumerate(key_discussions[:15]):
            # æ ¼å¼åŒ–æ—¶é—´
            time_str = datetime.fromtimestamp(discussion['time']).strftime('%m-%d %H:%M')
            
            discussions_html += f"""
            <div class="discussion-item">
                <div class="discussion-sender">{discussion['sender']}</div>
                <div class="discussion-content">{discussion['content']}</div>
                <div class="discussion-time">{time_str}</div>
            </div>
            """
        
        return discussions_html

    def _generate_discussion_sessions_for_template(self, discussion_sessions: List[Dict]) -> str:
        """
        ä¸ºæ¨¡æ¿ç”Ÿæˆè®¨è®ºä¼šè¯HTML
        """
        if not discussion_sessions:
            return "<div style='color: #666; text-align: center; padding: 20px; grid-column: 1 / -1;'>æš‚æ— è®¨è®ºä¼šè¯</div>"
        
        sessions_html = ""
        for i, session in enumerate(discussion_sessions[:10]):
            messages_html = ""
            for msg in session['messages'][:8]:  # é™åˆ¶æ¯ä¸ªä¼šè¯çš„æ¶ˆæ¯æ•°
                time_str = datetime.fromtimestamp(msg['time']).strftime('%H:%M')
                messages_html += f"""
                <div class="session-message">
                    <div class="session-sender">{msg['sender']}</div>
                    <div class="session-text">{msg['content']}</div>
                    <div class="session-time">{time_str}</div>
                </div>
                """
            
            # ä¼šè¯çŠ¶æ€æ˜¾ç¤º
            status_class = "session-completed" if session['status']['is_completed'] else "session-incomplete"
            status_text = "å·²å®Œæˆ" if session['status']['is_completed'] else "æœªå®Œæˆ"
            result_text = session['status']['result_summary']
            
            sessions_html += f"""
            <div class="session-item">
                <div class="session-header">
                    <div class="session-title">ä¼šè¯ #{i+1}</div>
                    <div class="session-duration">{session['message_count']}æ¡æ¶ˆæ¯</div>
                </div>
                {messages_html}
                <div class="session-status {status_class}">
                    çŠ¶æ€: {status_text}
                    <div class="session-result">ç»“æœ: {result_text}</div>
                </div>
            </div>
            """
        
        return sessions_html

    def generate_text_report(self, analysis_result: Dict) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æŠ¥å‘Š
        """
        report = f"""
=== ç¾¤èŠè¯é¢˜åˆ†ææŠ¥å‘Š ===
å…³é”®è¯: {analysis_result['keyword']}
ç¾¤å·: {analysis_result['group_id']}
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:
- ç›¸å…³æ¶ˆæ¯æ•°: {analysis_result['total_messages']}
- å‚ä¸äººæ•°: {len(analysis_result['participants'])}
- æ´»è·ƒç”¨æˆ·: {len(analysis_result['top_contributors'])}
- è®¨è®ºä¼šè¯: {len(analysis_result['discussion_sessions'])}

ğŸ† ä¸»è¦è´¡çŒ®è€…:
        """
        
        for name, count in list(analysis_result['top_contributors'].items())[:10]:
            report += f"- {name}: {count}æ¡æ¶ˆæ¯\n"
        
        report += f"\nğŸ“‹ è¯é¢˜æ€»ç»“:\n{analysis_result.get('topic_summary', 'æš‚æ— æ™ºèƒ½åˆ†æç»“æœ')}"
        
        report += "\n\nğŸ’¬ å…³é”®è®¨è®ºå†…å®¹:\n"
        for i, discussion in enumerate(analysis_result['key_discussions'][:8], 1):
            time_str = datetime.fromtimestamp(discussion['time']).strftime('%m-%d %H:%M')
            report += f"{i}. {discussion['sender']} ({time_str}): {discussion['content']}\n"
        
        report += "\nğŸ”— è®¨è®ºä¼šè¯:\n"
        for i, session in enumerate(analysis_result['discussion_sessions'][:5], 1):
            start_time = datetime.fromtimestamp(session['start_time']).strftime('%m-%d %H:%M')
            end_time = datetime.fromtimestamp(session['end_time']).strftime('%H:%M')
            status = "å·²å®Œæˆ" if session['status']['is_completed'] else "æœªå®Œæˆ"
            result = session['status']['result_summary']
            
            report += f"ä¼šè¯ {i} ({session['message_count']}æ¡æ¶ˆæ¯, {start_time}-{end_time}, {status}):\n"
            report += f"  ç»“æœ: {result}\n"
            
            for j, msg in enumerate(session['messages'][:5], 1):
                time_str = datetime.fromtimestamp(msg['time']).strftime('%H:%M')
                report += f"  {j}. {msg['sender']} ({time_str}): {msg['content']}\n"
            report += "\n"
        
        return report
